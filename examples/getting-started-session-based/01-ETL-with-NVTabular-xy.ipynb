{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7783917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2022 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ======================================================================\n",
    "\n",
    "# Each user is responsible for checking the content of datasets and the\n",
    "# applicable licenses and determining if suitable for the intended use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba6b360",
   "metadata": {},
   "source": [
    "<img src=\"https://developer.download.nvidia.com/notebooks/dlsw-notebooks/merlin_transformers4rec_getting-started-session-based-01-etl-with-nvtabular/nvidia_logo.png\" style=\"width: 90px; float: right;\">\n",
    "\n",
    "# ETL with NVTabular"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6085c0",
   "metadata": {},
   "source": [
    "In this notebook we are going to generate synthetic data and then create sequential features with [NVTabular](https://github.com/NVIDIA-Merlin/NVTabular). Such data will be used in the next notebook to train a session-based recommendation model.\n",
    "\n",
    "NVTabular is a feature engineering and preprocessing library for tabular data designed to quickly and easily manipulate terabyte scale datasets used to train deep learning based recommender systems. It provides a high level abstraction to simplify code and accelerates computation on the GPU using the RAPIDS cuDF library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add26d16",
   "metadata": {},
   "source": [
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e8dae24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/intel/oneapi/intelpython/latest/envs/transformer4rec/lib/python3.9/site-packages/merlin/dtypes/mappings/tf.py:52: UserWarning: Tensorflow dtype mappings did not load successfully due to an error: No module named 'tensorflow'\n",
      "  warn(f\"Tensorflow dtype mappings did not load successfully due to an error: {exc.msg}\")\n",
      "/opt/intel/oneapi/intelpython/latest/envs/transformer4rec/lib/python3.9/site-packages/merlin/dtypes/mappings/triton.py:53: UserWarning: Triton dtype mappings did not load successfully due to an error: No module named 'tritonclient'\n",
      "  warn(f\"Triton dtype mappings did not load successfully due to an error: {exc.msg}\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import glob\n",
    "\n",
    "# import cudf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nvtabular as nvt\n",
    "from nvtabular.ops import *\n",
    "from merlin.schema.tags import Tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3206b3f",
   "metadata": {},
   "source": [
    "### Define Input/Output Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "105dd71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DATA_DIR = os.environ.get(\"INPUT_DATA_DIR\", \"./data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a96708d7-c6bd-4587-b69a-2d7a24aaeea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data/'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_DATA_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36498a01",
   "metadata": {},
   "source": [
    "## Create a Synthetic Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "929036ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ROWS = os.environ.get(\"NUM_ROWS\", 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b6453d3-e5be-40ce-baaa-ca84a5857cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_tailed_item_distribution = np.clip(np.random.lognormal(3., 1., int(NUM_ROWS)).astype(np.int32), 1, 50000)\n",
    "# generate random item interaction features \n",
    "df = pd.DataFrame(np.random.randint(70000, 90000, int(NUM_ROWS)), columns=['session_id'])\n",
    "df['item_id'] = long_tailed_item_distribution\n",
    "\n",
    "# generate category mapping for each item-id\n",
    "df['category'] = pd.cut(df['item_id'], bins=334, labels=np.arange(1, 335)).astype(np.int32)\n",
    "df['age_days'] = np.random.uniform(0, 1, int(NUM_ROWS)).astype(np.float32)\n",
    "df['weekday_sin']= np.random.uniform(0, 1, int(NUM_ROWS)).astype(np.float32)\n",
    "\n",
    "# generate day mapping for each session \n",
    "map_day = dict(zip(df.session_id.unique(), np.random.randint(1, 10, size=(df.session_id.nunique()))))\n",
    "df['day'] =  df.session_id.map(map_day)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd861fcd",
   "metadata": {},
   "source": [
    "Visualize couple of rows of the synthetic dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5fa9320-7935-4a4c-ad7d-8f9e2b90801c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>category</th>\n",
       "      <th>age_days</th>\n",
       "      <th>weekday_sin</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78814</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>0.935278</td>\n",
       "      <td>0.764605</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87422</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>0.527721</td>\n",
       "      <td>0.237671</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>87958</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>0.387662</td>\n",
       "      <td>0.086010</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70729</td>\n",
       "      <td>47</td>\n",
       "      <td>13</td>\n",
       "      <td>0.956692</td>\n",
       "      <td>0.828015</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72325</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>0.444470</td>\n",
       "      <td>0.214215</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_id  item_id  category  age_days  weekday_sin  day\n",
       "0       78814       17         5  0.935278     0.764605    5\n",
       "1       87422       13         4  0.527721     0.237671    3\n",
       "2       87958       16         5  0.387662     0.086010    9\n",
       "3       70729       47        13  0.956692     0.828015    6\n",
       "4       72325       26         7  0.444470     0.214215    4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae36e04",
   "metadata": {},
   "source": [
    "## Feature Engineering with NVTabular"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139de226",
   "metadata": {},
   "source": [
    "Deep Learning models require dense input features. Categorical features are sparse, and need to be represented by dense embeddings in the model. To allow for that, categorical features first need to be encoded as contiguous integers `(0, ..., |C|)`, where `|C|` is the feature cardinality (number of unique values), so that their embeddings can be efficiently stored in embedding layers.  We will use NVTabular to preprocess the categorical features, so that all categorical columns are encoded as contiguous integers. Note that the `Categorify` op encodes `nulls` to `1`, OOVs to `2` automatically. We preserve `0` for padding. The encoding of other categories starts from `3`. In our synthetic dataset we do not have any nulls. On the other hand `0` is used for padding the sequences in input block. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b3bb9c",
   "metadata": {},
   "source": [
    "Here our goal is to create sequential features. To do so, we are grouping the features together at the session level in the following cell. In this synthetically generated example dataset, we do not have a timestamp column, but if we had one (that's the case for most real-world datasets), we would be sorting the interactions by the timestamp column as in this [example notebook](../end-to-end-session-based/01-ETL-with-NVTabular.ipynb). Note that we also trim each feature sequence in a  session to a certain length. Here, we use the NVTabular library so that we can easily preprocess and create features on GPU with a few lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a256f195",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/intel/oneapi/intelpython/latest/envs/transformer4rec/lib/python3.9/site-packages/merlin/io/dataset.py:267: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
      "  warnings.warn(\n",
      "/opt/intel/oneapi/intelpython/latest/envs/transformer4rec/lib/python3.9/site-packages/merlin/io/dataset.py:267: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
      "  warnings.warn(\n",
      "/opt/intel/oneapi/intelpython/latest/envs/transformer4rec/lib/python3.9/site-packages/merlin/io/dataset.py:267: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "SESSIONS_MAX_LENGTH =20\n",
    "\n",
    "# Categorify categorical features\n",
    "categ_feats = ['item_id', 'category'] >> nvt.ops.Categorify()\n",
    "\n",
    "# Define Groupby Workflow\n",
    "groupby_feats = categ_feats + ['session_id', 'day', 'age_days', 'weekday_sin']\n",
    "\n",
    "# Group interaction features by session\n",
    "groupby_features = groupby_feats >> nvt.ops.Groupby(\n",
    "    groupby_cols=[\"session_id\"], \n",
    "    aggs={\n",
    "        \"item_id\": [\"list\", \"count\"],\n",
    "        \"category\": [\"list\"],     \n",
    "        \"day\": [\"first\"],\n",
    "        \"age_days\": [\"list\"],\n",
    "        'weekday_sin': [\"list\"],\n",
    "        },\n",
    "    name_sep=\"-\")\n",
    "\n",
    "# Select and truncate the sequential features\n",
    "sequence_features_truncated = (\n",
    "    groupby_features['category-list']\n",
    "    >> nvt.ops.ListSlice(-SESSIONS_MAX_LENGTH) \n",
    ")\n",
    "\n",
    "sequence_features_truncated_item = (\n",
    "    groupby_features['item_id-list']\n",
    "    >> nvt.ops.ListSlice(-SESSIONS_MAX_LENGTH) \n",
    "    >> TagAsItemID()\n",
    ")  \n",
    "sequence_features_truncated_cont = (\n",
    "    groupby_features['age_days-list', 'weekday_sin-list'] \n",
    "    >> nvt.ops.ListSlice(-SESSIONS_MAX_LENGTH) \n",
    "    >> nvt.ops.AddMetadata(tags=[Tags.CONTINUOUS])\n",
    ")\n",
    "\n",
    "# Filter out sessions with length 1 (not valid for next-item prediction training and evaluation)\n",
    "MINIMUM_SESSION_LENGTH = 2\n",
    "selected_features = (\n",
    "    groupby_features['item_id-count', 'day-first', 'session_id'] + \n",
    "    sequence_features_truncated_item +\n",
    "    sequence_features_truncated + \n",
    "    sequence_features_truncated_cont\n",
    ")\n",
    "    \n",
    "filtered_sessions = selected_features >> nvt.ops.Filter(f=lambda df: df[\"item_id-count\"] >= MINIMUM_SESSION_LENGTH)\n",
    "\n",
    "seq_feats_list = filtered_sessions['item_id-list', 'category-list', 'age_days-list', 'weekday_sin-list'] >>  nvt.ops.ValueCount()\n",
    "\n",
    "workflow = nvt.Workflow(filtered_sessions['session_id', 'day-first'] + seq_feats_list)\n",
    "\n",
    "dataset = nvt.Dataset(df)\n",
    "\n",
    "# Generate statistics for the features and export parquet files\n",
    "# this step will generate the schema file\n",
    "workflow.fit_transform(dataset).to_parquet(os.path.join(INPUT_DATA_DIR, \"processed_nvt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2458c28f",
   "metadata": {},
   "source": [
    "It is possible to save the preprocessing workflow. That is useful to apply the same preprocessing to other data (with the same schema) and also to deploy the session-based recommendation pipeline to Triton Inference Server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78e42cbf-edd6-44af-af23-c026edb578c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>tags</th>\n",
       "      <th>dtype</th>\n",
       "      <th>is_list</th>\n",
       "      <th>is_ragged</th>\n",
       "      <th>properties.num_buckets</th>\n",
       "      <th>properties.freq_threshold</th>\n",
       "      <th>properties.max_size</th>\n",
       "      <th>properties.cat_path</th>\n",
       "      <th>properties.domain.min</th>\n",
       "      <th>properties.domain.max</th>\n",
       "      <th>properties.domain.name</th>\n",
       "      <th>properties.embedding_sizes.cardinality</th>\n",
       "      <th>properties.embedding_sizes.dimension</th>\n",
       "      <th>properties.value_count.min</th>\n",
       "      <th>properties.value_count.max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>session_id</td>\n",
       "      <td>()</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>day-first</td>\n",
       "      <td>()</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>item_id-list</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.ID, Tags.LIST, Tags.ITEM)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.item_id.parquet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>506.0</td>\n",
       "      <td>item_id</td>\n",
       "      <td>507.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>category-list</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.LIST)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.category.parquet</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>category</td>\n",
       "      <td>186.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>age_days-list</td>\n",
       "      <td>(Tags.CONTINUOUS, Tags.LIST)</td>\n",
       "      <td>DType(name='float32', element_type=&lt;ElementTyp...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>weekday_sin-list</td>\n",
       "      <td>(Tags.CONTINUOUS, Tags.LIST)</td>\n",
       "      <td>DType(name='float32', element_type=&lt;ElementTyp...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "[{'name': 'session_id', 'tags': set(), 'properties': {}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None),))), 'is_list': False, 'is_ragged': False}, {'name': 'day-first', 'tags': set(), 'properties': {}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None),))), 'is_list': False, 'is_ragged': False}, {'name': 'item_id-list', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.ID: 'id'>, <Tags.LIST: 'list'>, <Tags.ITEM: 'item'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'cat_path': './/categories/unique.item_id.parquet', 'domain': {'min': 0, 'max': 506, 'name': 'item_id'}, 'embedding_sizes': {'cardinality': 507, 'dimension': 52}, 'value_count': {'min': 2, 'max': 14}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=2, max=14)))), 'is_list': True, 'is_ragged': True}, {'name': 'category-list', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.LIST: 'list'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0, 'max_size': 0, 'cat_path': './/categories/unique.category.parquet', 'domain': {'min': 0, 'max': 185, 'name': 'category'}, 'embedding_sizes': {'cardinality': 186, 'dimension': 30}, 'value_count': {'min': 2, 'max': 14}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=2, max=14)))), 'is_list': True, 'is_ragged': True}, {'name': 'age_days-list', 'tags': {<Tags.CONTINUOUS: 'continuous'>, <Tags.LIST: 'list'>}, 'properties': {'value_count': {'min': 2, 'max': 14}}, 'dtype': DType(name='float32', element_type=<ElementType.Float: 'float'>, element_size=32, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=2, max=14)))), 'is_list': True, 'is_ragged': True}, {'name': 'weekday_sin-list', 'tags': {<Tags.CONTINUOUS: 'continuous'>, <Tags.LIST: 'list'>}, 'properties': {'value_count': {'min': 2, 'max': 14}}, 'dtype': DType(name='float32', element_type=<ElementType.Float: 'float'>, element_size=32, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=2, max=14)))), 'is_list': True, 'is_ragged': True}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.output_schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2b54bb-4549-49a3-89bb-1f573a426aca",
   "metadata": {},
   "source": [
    "Save NVTabular workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f498dce-69eb-4f88-8ddd-8629558825df",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.save(os.path.join(INPUT_DATA_DIR, \"workflow_etl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ac6b52-5b61-4771-867d-3d6d2eb364ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02a41961",
   "metadata": {},
   "source": [
    "## Export pre-processed data by day"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cedca3",
   "metadata": {},
   "source": [
    "In this example we are going to split the preprocessed parquet files by days, to allow for temporal training and evaluation. There will be a folder for each day and three parquet files within each day folder: `train.parquet`, `validation.parquet` and `test.parquet`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12d3e59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = os.environ.get(\"OUTPUT_DIR\",os.path.join(INPUT_DATA_DIR, \"sessions_by_day\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "603fb27a-0c64-43eb-be79-42213944990b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the processed parquet file\n",
    "sessions_gdf = pd.read_parquet(os.path.join(INPUT_DATA_DIR, \"processed_nvt/part_0.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c537a248-059e-4db9-8b62-9681175f0193",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>day-first</th>\n",
       "      <th>item_id-list</th>\n",
       "      <th>category-list</th>\n",
       "      <th>age_days-list</th>\n",
       "      <th>weekday_sin-list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70000</td>\n",
       "      <td>8</td>\n",
       "      <td>[103, 25, 60]</td>\n",
       "      <td>[33, 8, 20]</td>\n",
       "      <td>[0.7048097848892212, 0.6903286576271057, 0.667...</td>\n",
       "      <td>[0.2934705317020416, 0.3389386236667633, 0.052...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70001</td>\n",
       "      <td>5</td>\n",
       "      <td>[27, 4, 5, 15, 17]</td>\n",
       "      <td>[8, 3, 3, 6, 6]</td>\n",
       "      <td>[0.5091915726661682, 0.09631510078907013, 0.16...</td>\n",
       "      <td>[0.01199796050786972, 0.4487989842891693, 0.95...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70002</td>\n",
       "      <td>7</td>\n",
       "      <td>[7, 11, 18, 18, 14, 44]</td>\n",
       "      <td>[5, 4, 6, 6, 4, 13]</td>\n",
       "      <td>[0.7389612793922424, 0.3185826539993286, 0.915...</td>\n",
       "      <td>[0.4517076313495636, 0.49958136677742004, 0.89...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70003</td>\n",
       "      <td>1</td>\n",
       "      <td>[6, 119, 55, 91, 12, 11, 7]</td>\n",
       "      <td>[3, 37, 17, 26, 4, 4, 5]</td>\n",
       "      <td>[0.8941054344177246, 0.6713675260543823, 0.135...</td>\n",
       "      <td>[0.32163500785827637, 0.5422960519790649, 0.85...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70004</td>\n",
       "      <td>6</td>\n",
       "      <td>[55, 57]</td>\n",
       "      <td>[17, 20]</td>\n",
       "      <td>[0.6114782691001892, 0.7743163704872131]</td>\n",
       "      <td>[0.5357045531272888, 0.24191606044769287]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19209</th>\n",
       "      <td>89995</td>\n",
       "      <td>6</td>\n",
       "      <td>[28, 4, 28, 81, 3, 296]</td>\n",
       "      <td>[11, 3, 11, 23, 3, 72]</td>\n",
       "      <td>[0.7987788319587708, 0.17112861573696136, 0.13...</td>\n",
       "      <td>[0.08514165133237839, 0.1657770872116089, 0.47...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19210</th>\n",
       "      <td>89996</td>\n",
       "      <td>5</td>\n",
       "      <td>[14, 14, 42, 35]</td>\n",
       "      <td>[4, 4, 14, 7]</td>\n",
       "      <td>[0.805230438709259, 0.066165991127491, 0.50335...</td>\n",
       "      <td>[0.3799225687980652, 0.5059230327606201, 0.182...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19211</th>\n",
       "      <td>89997</td>\n",
       "      <td>7</td>\n",
       "      <td>[5, 32, 7, 134, 16]</td>\n",
       "      <td>[3, 10, 5, 36, 7]</td>\n",
       "      <td>[0.6572467684745789, 0.3500416874885559, 0.884...</td>\n",
       "      <td>[0.914212167263031, 0.04325936362147331, 0.450...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19212</th>\n",
       "      <td>89998</td>\n",
       "      <td>9</td>\n",
       "      <td>[6, 6, 23, 87]</td>\n",
       "      <td>[3, 3, 9, 25]</td>\n",
       "      <td>[0.42906442284584045, 0.6422862410545349, 0.33...</td>\n",
       "      <td>[0.6524897813796997, 0.17047034204006195, 0.60...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19213</th>\n",
       "      <td>89999</td>\n",
       "      <td>1</td>\n",
       "      <td>[29, 18, 47, 119, 44, 97, 20, 12, 111, 8]</td>\n",
       "      <td>[11, 6, 16, 37, 13, 31, 9, 4, 30, 5]</td>\n",
       "      <td>[0.09996724128723145, 0.35283565521240234, 0.6...</td>\n",
       "      <td>[0.307969868183136, 0.29971158504486084, 0.135...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19214 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       session_id  day-first                               item_id-list  \\\n",
       "0           70000          8                              [103, 25, 60]   \n",
       "1           70001          5                         [27, 4, 5, 15, 17]   \n",
       "2           70002          7                    [7, 11, 18, 18, 14, 44]   \n",
       "3           70003          1                [6, 119, 55, 91, 12, 11, 7]   \n",
       "4           70004          6                                   [55, 57]   \n",
       "...           ...        ...                                        ...   \n",
       "19209       89995          6                    [28, 4, 28, 81, 3, 296]   \n",
       "19210       89996          5                           [14, 14, 42, 35]   \n",
       "19211       89997          7                        [5, 32, 7, 134, 16]   \n",
       "19212       89998          9                             [6, 6, 23, 87]   \n",
       "19213       89999          1  [29, 18, 47, 119, 44, 97, 20, 12, 111, 8]   \n",
       "\n",
       "                              category-list  \\\n",
       "0                               [33, 8, 20]   \n",
       "1                           [8, 3, 3, 6, 6]   \n",
       "2                       [5, 4, 6, 6, 4, 13]   \n",
       "3                  [3, 37, 17, 26, 4, 4, 5]   \n",
       "4                                  [17, 20]   \n",
       "...                                     ...   \n",
       "19209                [11, 3, 11, 23, 3, 72]   \n",
       "19210                         [4, 4, 14, 7]   \n",
       "19211                     [3, 10, 5, 36, 7]   \n",
       "19212                         [3, 3, 9, 25]   \n",
       "19213  [11, 6, 16, 37, 13, 31, 9, 4, 30, 5]   \n",
       "\n",
       "                                           age_days-list  \\\n",
       "0      [0.7048097848892212, 0.6903286576271057, 0.667...   \n",
       "1      [0.5091915726661682, 0.09631510078907013, 0.16...   \n",
       "2      [0.7389612793922424, 0.3185826539993286, 0.915...   \n",
       "3      [0.8941054344177246, 0.6713675260543823, 0.135...   \n",
       "4               [0.6114782691001892, 0.7743163704872131]   \n",
       "...                                                  ...   \n",
       "19209  [0.7987788319587708, 0.17112861573696136, 0.13...   \n",
       "19210  [0.805230438709259, 0.066165991127491, 0.50335...   \n",
       "19211  [0.6572467684745789, 0.3500416874885559, 0.884...   \n",
       "19212  [0.42906442284584045, 0.6422862410545349, 0.33...   \n",
       "19213  [0.09996724128723145, 0.35283565521240234, 0.6...   \n",
       "\n",
       "                                        weekday_sin-list  \n",
       "0      [0.2934705317020416, 0.3389386236667633, 0.052...  \n",
       "1      [0.01199796050786972, 0.4487989842891693, 0.95...  \n",
       "2      [0.4517076313495636, 0.49958136677742004, 0.89...  \n",
       "3      [0.32163500785827637, 0.5422960519790649, 0.85...  \n",
       "4              [0.5357045531272888, 0.24191606044769287]  \n",
       "...                                                  ...  \n",
       "19209  [0.08514165133237839, 0.1657770872116089, 0.47...  \n",
       "19210  [0.3799225687980652, 0.5059230327606201, 0.182...  \n",
       "19211  [0.914212167263031, 0.04325936362147331, 0.450...  \n",
       "19212  [0.6524897813796997, 0.17047034204006195, 0.60...  \n",
       "19213  [0.307969868183136, 0.29971158504486084, 0.135...  \n",
       "\n",
       "[19214 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sessions_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c67a92b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers4rec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m save_time_based_splits\n\u001b[0;32m----> 2\u001b[0m \u001b[43msave_time_based_splits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnvt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43msessions_gdf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                       \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mOUTPUT_DIR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mpartition_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mday-first\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mtimestamp_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msession_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mcpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m                      \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/vmagent/app/Transformers4Rec/transformers4rec/utils/data_utils.py:204\u001b[0m, in \u001b[0;36msave_time_based_splits\u001b[0;34m(data, output_dir, partition_col, timestamp_col, test_size, val_size, overwrite, cpu)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Split a dataset into time-based splits.\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;124;03mNote, this function requires Rapids dependencies to be installed:\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;124;03mcudf, cupy and dask_cudf\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;124;03m    Whether or not to run the computation on the CPU.\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cpu:\n\u001b[0;32m--> 204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_save_time_based_splits_cpu\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartition_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartition_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimestamp_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimestamp_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _save_time_based_splits_gpu(\n\u001b[1;32m    215\u001b[0m         data,\n\u001b[1;32m    216\u001b[0m         output_dir\u001b[38;5;241m=\u001b[39moutput_dir,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    221\u001b[0m         overwrite\u001b[38;5;241m=\u001b[39moverwrite,\n\u001b[1;32m    222\u001b[0m     )\n",
      "File \u001b[0;32m/home/vmagent/app/Transformers4Rec/transformers4rec/utils/data_utils.py:357\u001b[0m, in \u001b[0;36m_save_time_based_splits_cpu\u001b[0;34m(data, output_dir, partition_col, timestamp_col, test_size, val_size, overwrite)\u001b[0m\n\u001b[1;32m    354\u001b[0m     shutil\u001b[38;5;241m.\u001b[39mrmtree(output_dir)\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tempfile\u001b[38;5;241m.\u001b[39mTemporaryDirectory() \u001b[38;5;28;01mas\u001b[39;00m tmpdirname:\n\u001b[0;32m--> 357\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtmpdirname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartition_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartition_col\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m     time_dirs \u001b[38;5;241m=\u001b[39m [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(tmpdirname)) \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mstartswith(partition_col[\u001b[38;5;241m0\u001b[39m])]\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m tqdm(time_dirs, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating time-based splits\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/intel/oneapi/intelpython/latest/envs/transformer4rec/lib/python3.9/site-packages/merlin/io/dataset.py:982\u001b[0m, in \u001b[0;36mDataset.to_parquet\u001b[0;34m(self, output_path, shuffle, preserve_files, output_files, out_files_per_proc, row_group_size, num_threads, dtypes, cats, conts, labels, suffix, partition_on, method, write_hugectr_keyset)\u001b[0m\n\u001b[1;32m    979\u001b[0m tf_metadata\u001b[38;5;241m.\u001b[39mto_json_file(metadata_path)\n\u001b[1;32m    981\u001b[0m \u001b[38;5;66;03m# Output dask_cudf DataFrame to dataset\u001b[39;00m\n\u001b[0;32m--> 982\u001b[0m \u001b[43m_ddf_to_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mddf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    987\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout_files_per_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    989\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    990\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconts\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    991\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparquet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    993\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    994\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    995\u001b[0m \u001b[43m    \u001b[49m\u001b[43msuffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    996\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrow_group_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow_group_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    997\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpartition_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartition_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    998\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mwrite_hugectr_keyset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    999\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/intel/oneapi/intelpython/latest/envs/transformer4rec/lib/python3.9/site-packages/merlin/io/dask.py:420\u001b[0m, in \u001b[0;36m_ddf_to_dataset\u001b[0;34m(ddf, fs, output_path, shuffle, file_partition_map, out_files_per_proc, cat_names, cont_names, label_names, output_format, num_threads, cpu, suffix, row_group_size, partition_on, schema)\u001b[0m\n\u001b[1;32m    418\u001b[0m     out \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mcompute(out)\u001b[38;5;241m.\u001b[39mresult()\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 420\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mdask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msynchronous\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cached_writers:\n\u001b[1;32m    423\u001b[0m     \u001b[38;5;66;03m# Follow-up Shuffling and _metadata creation\u001b[39;00m\n\u001b[1;32m    424\u001b[0m     _finish_dataset(client, ddf, output_path, fs, output_format, cpu, schema)\n",
      "File \u001b[0;32m/opt/intel/oneapi/intelpython/latest/envs/transformer4rec/lib/python3.9/site-packages/dask/base.py:628\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    625\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[0;32m--> 628\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[0;32m/opt/intel/oneapi/intelpython/latest/envs/transformer4rec/lib/python3.9/site-packages/merlin/core/dispatch.py:69\u001b[0m, in \u001b[0;36mannotate.<locals>.inner1.<locals>.inner2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner2\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/intel/oneapi/intelpython/latest/envs/transformer4rec/lib/python3.9/site-packages/merlin/io/dask.py:155\u001b[0m, in \u001b[0;36m_write_partitioned\u001b[0;34m(df, filename, output_path, partition_cols, shuffle, fs, cat_names, cont_names, label_names, output_format, num_threads, cpu, row_group_size)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo data left to save outside partition columns\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;66;03m# Partition the input data\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m fns, dfs \u001b[38;5;241m=\u001b[39m \u001b[43m_get_partition_groups\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m writer \u001b[38;5;241m=\u001b[39m writer_factory(\n\u001b[1;32m    157\u001b[0m     output_format,\n\u001b[1;32m    158\u001b[0m     output_path,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    164\u001b[0m     row_group_size\u001b[38;5;241m=\u001b[39mrow_group_size,\n\u001b[1;32m    165\u001b[0m )\n\u001b[1;32m    166\u001b[0m writer\u001b[38;5;241m.\u001b[39mset_col_names(labels\u001b[38;5;241m=\u001b[39mlabel_names, cats\u001b[38;5;241m=\u001b[39mcat_names, conts\u001b[38;5;241m=\u001b[39mcont_names)\n",
      "File \u001b[0;32m/opt/intel/oneapi/intelpython/latest/envs/transformer4rec/lib/python3.9/site-packages/merlin/io/dask.py:115\u001b[0m, in \u001b[0;36m_get_partition_groups\u001b[0;34m(df, partition_cols, fs, output_path, filename)\u001b[0m\n\u001b[1;32m    113\u001b[0m subgroups, fns \u001b[38;5;241m=\u001b[39m [], []\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(splits) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 115\u001b[0m     sub_df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[splits[i][\u001b[38;5;241m0\u001b[39m] : \u001b[43msplits\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sub_df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sub_df) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    117\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "from transformers4rec.utils.data_utils import save_time_based_splits\n",
    "save_time_based_splits(data=nvt.Dataset(sessions_gdf),\n",
    "                       output_dir= OUTPUT_DIR,\n",
    "                       partition_col='day-first',\n",
    "                       timestamp_col='session_id', \n",
    "                       cpu=True\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b72337b",
   "metadata": {},
   "source": [
    "## Check out the preprocessed outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd04ec82",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATHS = os.path.join(OUTPUT_DIR, \"1\", \"train.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e5e6358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>item_id-list</th>\n",
       "      <th>category-list</th>\n",
       "      <th>age_days-list</th>\n",
       "      <th>weekday_sin-list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70000</td>\n",
       "      <td>[306, 5, 40, 17]</td>\n",
       "      <td>[104, 3, 12, 6]</td>\n",
       "      <td>[0.044022594, 0.34956282, 0.7326993, 0.09403495]</td>\n",
       "      <td>[0.7417527, 0.60325843, 0.07417604, 0.28911334]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70001</td>\n",
       "      <td>[43, 20, 69, 8, 57]</td>\n",
       "      <td>[13, 6, 21, 3, 16]</td>\n",
       "      <td>[0.8072543, 0.28916782, 0.04966254, 0.08417622...</td>\n",
       "      <td>[0.7995051, 0.86722755, 0.84298295, 0.15793765...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70002</td>\n",
       "      <td>[137, 35, 37, 85, 65, 5]</td>\n",
       "      <td>[37, 10, 11, 22, 18, 3]</td>\n",
       "      <td>[0.04696693, 0.94499177, 0.2922437, 0.83047426...</td>\n",
       "      <td>[0.72519076, 0.92308444, 0.40120387, 0.3821016...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70007</td>\n",
       "      <td>[28, 9, 153, 74, 53, 15, 173]</td>\n",
       "      <td>[9, 4, 39, 20, 15, 5, 46]</td>\n",
       "      <td>[0.4730765, 0.69885534, 0.034774363, 0.7225920...</td>\n",
       "      <td>[0.33613566, 0.660022, 0.72897774, 0.66087157,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>70021</td>\n",
       "      <td>[59, 32, 11, 21, 23, 23, 9, 15]</td>\n",
       "      <td>[17, 10, 7, 7, 8, 8, 4, 5]</td>\n",
       "      <td>[0.07898139, 0.27463168, 0.1885847, 0.5203435,...</td>\n",
       "      <td>[0.39734098, 0.74895114, 0.43540764, 0.8372503...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   session_id                     item_id-list               category-list  \\\n",
       "0       70000                 [306, 5, 40, 17]             [104, 3, 12, 6]   \n",
       "1       70001              [43, 20, 69, 8, 57]          [13, 6, 21, 3, 16]   \n",
       "2       70002         [137, 35, 37, 85, 65, 5]     [37, 10, 11, 22, 18, 3]   \n",
       "4       70007    [28, 9, 153, 74, 53, 15, 173]   [9, 4, 39, 20, 15, 5, 46]   \n",
       "5       70021  [59, 32, 11, 21, 23, 23, 9, 15]  [17, 10, 7, 7, 8, 8, 4, 5]   \n",
       "\n",
       "                                       age_days-list  \\\n",
       "0   [0.044022594, 0.34956282, 0.7326993, 0.09403495]   \n",
       "1  [0.8072543, 0.28916782, 0.04966254, 0.08417622...   \n",
       "2  [0.04696693, 0.94499177, 0.2922437, 0.83047426...   \n",
       "4  [0.4730765, 0.69885534, 0.034774363, 0.7225920...   \n",
       "5  [0.07898139, 0.27463168, 0.1885847, 0.5203435,...   \n",
       "\n",
       "                                    weekday_sin-list  \n",
       "0    [0.7417527, 0.60325843, 0.07417604, 0.28911334]  \n",
       "1  [0.7995051, 0.86722755, 0.84298295, 0.15793765...  \n",
       "2  [0.72519076, 0.92308444, 0.40120387, 0.3821016...  \n",
       "4  [0.33613566, 0.660022, 0.72897774, 0.66087157,...  \n",
       "5  [0.39734098, 0.74895114, 0.43540764, 0.8372503...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(TRAIN_PATHS)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a687f998-8905-42a4-bb92-d1f5244860b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6461a96",
   "metadata": {},
   "source": [
    "You have  just created session-level features to train a session-based recommendation model using NVTabular. Now you can move to the the next notebook,`02-session-based-XLNet-with-PyT.ipynb` to train a session-based recommendation model using [XLNet](https://arxiv.org/abs/1906.08237), one of the state-of-the-art NLP model. Please shut down this kernel to free the GPU memory before you start the next one."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "d795d7ca5d3ec3bd6293cc80853205a74ce23d484a2b8f537732a716747107c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
